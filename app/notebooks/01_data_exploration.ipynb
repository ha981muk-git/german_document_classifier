{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28c8f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_dataset.py\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ca75622",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/data_synthetic\"  # folder where your synthetic txt files are stored\n",
    "output_path = \"../data/data_processed\"\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a2b5fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Collect and label all .txt files\n",
    "files = glob.glob(os.path.join(data_path, \"*.txt\"))\n",
    "data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a39b0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not files:\n",
    "    raise FileNotFoundError(f\"No .txt files found in '{data_path}'. Run make_synthetic_data.py first.\")\n",
    "\n",
    "for f in files:\n",
    "    with open(f, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read().strip()\n",
    "        # Extract label from filename prefix, e.g. \"invoice_12.txt\" -> \"invoice\"\n",
    "        filename = os.path.basename(f)\n",
    "        label = filename.split(\"_\")[0].lower()\n",
    "        data.append({\"filename\": filename, \"text\": text, \"label\": label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11bfb249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Label distribution:\n",
      "label\n",
      "reminder     200\n",
      "order        200\n",
      "invoice      200\n",
      "contract     200\n",
      "complaint    200\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "print(\"ðŸ“Š Label distribution:\")\n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "928fedd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 30806.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After preprocessing: 1000 samples\n",
      "label\n",
      "reminder     200\n",
      "order        200\n",
      "invoice      200\n",
      "contract     200\n",
      "complaint    200\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# Text preprocessing utilities\n",
    "def preprocess_text(text, min_words=4):\n",
    "    \"\"\"Clean a single text string.\n",
    "    - remove newlines\n",
    "    - remove HTML tags\n",
    "    - normalize whitespace\n",
    "    - remove unwanted characters while keeping common punctuation and currency symbols\n",
    "    - lower-case\n",
    "    - return None for very short texts\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return None\n",
    "    # ensure string\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    # Remove newline characters\n",
    "    text = text.replace('\\n', ' ')\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Keep letters, numbers, whitespace and common punctuation ($ â‚¬ % . , - /)\n",
    "    text = re.sub(r\"[^\\w\\s$â‚¬%.,/-]\", ' ', text)\n",
    "    # Lowercase & strip\n",
    "    text = text.strip().lower()\n",
    "    # Require a minimum number of words\n",
    "    if len(text.split()) < min_words:\n",
    "        return None\n",
    "    return text\n",
    "\n",
    "\n",
    "def apply_preprocessing(df, text_column='text', min_words=4):\n",
    "    \"\"\"Apply preprocessing to a dataframe column and drop empty results.\"\"\"\n",
    "    processed = []\n",
    "    for t in tqdm(df[text_column].fillna('').astype(str), desc='Preprocessing'):\n",
    "        processed.append(preprocess_text(t, min_words=min_words))\n",
    "    df[text_column] = processed\n",
    "    # Drop rows where preprocessing returned None\n",
    "    df = df[df[text_column].notna()].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Apply preprocessing before splitting the dataset\n",
    "df = apply_preprocessing(df, text_column='text', min_words=4)\n",
    "print(f\"After preprocessing: {len(df)} samples\")\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f945fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Save full labeled dataset\n",
    "df.to_csv(os.path.join(output_path, \"all_data.csv\"), index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a3bf7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Split into train, validation, test sets (80 / 10 / 10)\n",
    "# train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "# val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"label\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b49796db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_df.to_csv(os.path.join(output_path, \"train.csv\"), index=False, encoding=\"utf-8\")\n",
    "# val_df.to_csv(os.path.join(output_path, \"val.csv\"), index=False, encoding=\"utf-8\")\n",
    "# test_df.to_csv(os.path.join(output_path, \"test.csv\"), index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dca24b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Data preparation complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nâœ… Data preparation complete!\")\n",
    "# print(f\"Train set: {len(train_df)} | Validation set: {len(val_df)} | Test set: {len(test_df)}\")\n",
    "# print(f\"Labeled CSVs saved in '{output_path}/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04c44ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reminder_172.txt</td>\n",
       "      <td>letzte mahnung vor aussenstellung rechnung  re...</td>\n",
       "      <td>reminder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reminder_166.txt</td>\n",
       "      <td>erste mahnung mahnung zur rechnung nr. re-8676...</td>\n",
       "      <td>reminder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reminder_199.txt</td>\n",
       "      <td>erste mahnung mahnung zur rechnung nr. re-7506...</td>\n",
       "      <td>reminder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>order_138.txt</td>\n",
       "      <td>bestellung bestellnummer  po-2024-3137 bestell...</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>order_110.txt</td>\n",
       "      <td>dringende bestellung - eilt  bestellnummer  ei...</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>invoice_136.txt</td>\n",
       "      <td>abonnement-rechnung rechnung  abo-14446 abrech...</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>order_135.txt</td>\n",
       "      <td>bestellung bestellnummer  po-2024-3134 bestell...</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>complaint_2.txt</td>\n",
       "      <td>qualitÃ¤tsreklamation lieferung vom  11.11.2025...</td>\n",
       "      <td>complaint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>reminder_143.txt</td>\n",
       "      <td>freundliche erinnerung sehr geehrte damen und ...</td>\n",
       "      <td>reminder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>reminder_157.txt</td>\n",
       "      <td>freundliche erinnerung sehr geehrte damen und ...</td>\n",
       "      <td>reminder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename                                               text  \\\n",
       "0    reminder_172.txt  letzte mahnung vor aussenstellung rechnung  re...   \n",
       "1    reminder_166.txt  erste mahnung mahnung zur rechnung nr. re-8676...   \n",
       "2    reminder_199.txt  erste mahnung mahnung zur rechnung nr. re-7506...   \n",
       "3       order_138.txt  bestellung bestellnummer  po-2024-3137 bestell...   \n",
       "4       order_110.txt  dringende bestellung - eilt  bestellnummer  ei...   \n",
       "..                ...                                                ...   \n",
       "995   invoice_136.txt  abonnement-rechnung rechnung  abo-14446 abrech...   \n",
       "996     order_135.txt  bestellung bestellnummer  po-2024-3134 bestell...   \n",
       "997   complaint_2.txt  qualitÃ¤tsreklamation lieferung vom  11.11.2025...   \n",
       "998  reminder_143.txt  freundliche erinnerung sehr geehrte damen und ...   \n",
       "999  reminder_157.txt  freundliche erinnerung sehr geehrte damen und ...   \n",
       "\n",
       "         label  \n",
       "0     reminder  \n",
       "1     reminder  \n",
       "2     reminder  \n",
       "3        order  \n",
       "4        order  \n",
       "..         ...  \n",
       "995    invoice  \n",
       "996      order  \n",
       "997  complaint  \n",
       "998   reminder  \n",
       "999   reminder  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c6bb1",
   "metadata": {},
   "source": [
    "# Importing Dataset from Huggingface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0184b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c9e57aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from Hugging Face\n",
    "dataset = load_dataset(\"Aoschu/donut_model_data_for_german_invoice\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e34c8c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'ground_truth'],\n",
      "        num_rows: 97\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'ground_truth'],\n",
      "        num_rows: 14\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'ground_truth'],\n",
      "        num_rows: 18\n",
      "    })\n",
      "})\n",
      "\n",
      "Available splits: ['train', 'validation', 'test']\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset structure:\", dataset)\n",
    "print(\"\\nAvailable splits:\", list(dataset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d89c58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1414x2000 at 0x309178F40>, 'ground_truth': '{\"gt_parse\": {\"Der Name der Firma\": \"PaulCheung\", \"Die Adresse der Firma\": \"Paul CheungMayerhofer-Allee 812345 Freiberg\", \"Telefonnummer\": \"0123 5678-90\", \"Rechnungsdatum\": \"1234\", \"Summe\": \"7.735,00\\\\u20ac\", \"Der Name der Bank\": \"Freiberuflerbank\", \"IBAN\": \"DE12 3456 7890 1234 5678 90\"}}'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac8fb020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "example = dataset[\"train\"][3]\n",
    "img = example[\"image\"]\n",
    "img.show()  # opens in your image viewer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdad4418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image', 'ground_truth']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"gt_parse\": {\"Rechnungsdatum\": \"21.07.2021\", \"Falligkeitsdatum\": \"04.08.2021\", \"Summe\": \"595,00:\", \"Rechnungsnummer\": \"257\"}}'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset[\"train\"].column_names)\n",
    "example[\"ground_truth\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fe9d71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'ground_truth'],\n",
       "        num_rows: 97\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'ground_truth'],\n",
       "        num_rows: 14\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'ground_truth'],\n",
       "        num_rows: 18\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa818713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc-classifier-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
