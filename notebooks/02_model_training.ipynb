{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6defc7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f419f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace63f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Select device: prefer MPS on macOS, then CUDA, then CPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available(): \n",
    "    device = torch.device(\"cuda\")               \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using:\", device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24cbe3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31102, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a German BERT model from Hugging Face\n",
    "model_name = \"dbmdz/bert-base-german-cased\"\n",
    "\n",
    "# Load tokenizer and model for sequence classification\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=4,  # adjust if your dataset has a different number of labels\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb33c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reminder_172.txt</td>\n",
       "      <td>letzte mahnung vor aussenstellung rechnung  re...</td>\n",
       "      <td>reminder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reminder_166.txt</td>\n",
       "      <td>erste mahnung mahnung zur rechnung nr. re-8676...</td>\n",
       "      <td>reminder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reminder_199.txt</td>\n",
       "      <td>erste mahnung mahnung zur rechnung nr. re-7506...</td>\n",
       "      <td>reminder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>order_138.txt</td>\n",
       "      <td>bestellung bestellnummer  po-2024-3137 bestell...</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>order_110.txt</td>\n",
       "      <td>dringende bestellung - eilt  bestellnummer  ei...</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>contract_132.txt</td>\n",
       "      <td>software-lizenzvertrag zwischen bauer manufact...</td>\n",
       "      <td>contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>complaint_72.txt</td>\n",
       "      <td>qualitätsreklamation lieferung vom  11.11.2025...</td>\n",
       "      <td>complaint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>contract_5.txt</td>\n",
       "      <td>liefervertrag zwischen koch engineering   käuf...</td>\n",
       "      <td>contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>invoice_58.txt</td>\n",
       "      <td>koch engineering gartenstraße 12 frankfurt am ...</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>contract_17.txt</td>\n",
       "      <td>darlehensvertrag zwischen zimmermann tech   da...</td>\n",
       "      <td>contract</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename                                               text  \\\n",
       "0   reminder_172.txt  letzte mahnung vor aussenstellung rechnung  re...   \n",
       "1   reminder_166.txt  erste mahnung mahnung zur rechnung nr. re-8676...   \n",
       "2   reminder_199.txt  erste mahnung mahnung zur rechnung nr. re-7506...   \n",
       "3      order_138.txt  bestellung bestellnummer  po-2024-3137 bestell...   \n",
       "4      order_110.txt  dringende bestellung - eilt  bestellnummer  ei...   \n",
       "..               ...                                                ...   \n",
       "95  contract_132.txt  software-lizenzvertrag zwischen bauer manufact...   \n",
       "96  complaint_72.txt  qualitätsreklamation lieferung vom  11.11.2025...   \n",
       "97    contract_5.txt  liefervertrag zwischen koch engineering   käuf...   \n",
       "98    invoice_58.txt  koch engineering gartenstraße 12 frankfurt am ...   \n",
       "99   contract_17.txt  darlehensvertrag zwischen zimmermann tech   da...   \n",
       "\n",
       "        label  \n",
       "0    reminder  \n",
       "1    reminder  \n",
       "2    reminder  \n",
       "3       order  \n",
       "4       order  \n",
       "..        ...  \n",
       "95   contract  \n",
       "96  complaint  \n",
       "97   contract  \n",
       "98    invoice  \n",
       "99   contract  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/data_processed/all_data.csv')\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4d2f3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>letzte mahnung vor aussenstellung rechnung  re...</td>\n",
       "      <td>reminder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>erste mahnung mahnung zur rechnung nr. re-8676...</td>\n",
       "      <td>reminder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>erste mahnung mahnung zur rechnung nr. re-7506...</td>\n",
       "      <td>reminder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bestellung bestellnummer  po-2024-3137 bestell...</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dringende bestellung - eilt  bestellnummer  ei...</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  letzte mahnung vor aussenstellung rechnung  re...  reminder\n",
       "1  erste mahnung mahnung zur rechnung nr. re-8676...  reminder\n",
       "2  erste mahnung mahnung zur rechnung nr. re-7506...  reminder\n",
       "3  bestellung bestellnummer  po-2024-3137 bestell...     order\n",
       "4  dringende bestellung - eilt  bestellnummer  ei...     order"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['text','label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b356340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c134365b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>letzte mahnung vor aussenstellung rechnung  re...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>erste mahnung mahnung zur rechnung nr. re-8676...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>erste mahnung mahnung zur rechnung nr. re-7506...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bestellung bestellnummer  po-2024-3137 bestell...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dringende bestellung - eilt  bestellnummer  ei...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  letzte mahnung vor aussenstellung rechnung  re...      4\n",
       "1  erste mahnung mahnung zur rechnung nr. re-8676...      4\n",
       "2  erste mahnung mahnung zur rechnung nr. re-7506...      4\n",
       "3  bestellung bestellnummer  po-2024-3137 bestell...      3\n",
       "4  dringende bestellung - eilt  bestellnummer  ei...      3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "# Encode the labels\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32f3166c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 800\n",
      "Testing set size: 100\n",
      "Validating set size: 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Step 4: Split into train, validation, test sets (80 / 10 / 10)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"label\"], random_state=42)\n",
    "# No further splitting here — we already have pre-split train/test CSVs\n",
    "print(f'Training set size: {len(train_df)}')\n",
    "print(f'Testing set size: {len(test_df)}')\n",
    "print(f'Validating set size: {len(val_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf9a9cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "# convert the merged dataframe to a dictionary\n",
    "data_train_dict = train_df.to_dict('list')\n",
    "dataset_train = Dataset.from_dict(data_train_dict)\n",
    "data_train_dict = test_df.to_dict('list')\n",
    "dataset_test = Dataset.from_dict(data_train_dict)\n",
    "data_train_dict = val_df.to_dict('list')\n",
    "dataset_validation = Dataset.from_dict(data_train_dict)\n",
    "# create a dataset dictionary\n",
    "dataset = DatasetDict({'train': dataset_train,'test':dataset_test,'validation':dataset_validation})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "614cea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_p = []\n",
    "max_length=512\n",
    "def tokenize_data(example):\n",
    "    try:\n",
    "        return tokenizer(str(example['text']),\n",
    "                         padding='max_length',\n",
    "                         truncation=True,\n",
    "                         max_length=max_length,\n",
    "                      )\n",
    "    #truncation=True, padding=True ,max_length=128, return_overflowing_tokens=True,\n",
    "    except:\n",
    "        print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc96b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd143893a8f3406385115a1c941f817b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049a475484e04988b8cd570ca6310d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf26b55eb5b4d3b8d0016e253bfaadc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize_data ,remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff17c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "model_path = \"./../models/bert_finetuned_faker_dataset\"\n",
    "training_args = TrainingArguments(\n",
    "    model_path,\n",
    "    num_train_epochs=3,                    # Better results\n",
    "    save_total_limit=1,\n",
    "    learning_rate=3e-5,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,         # Eval can handle more\n",
    "    gradient_accumulation_steps=2,         # Effective batch_size=16\n",
    "    dataloader_num_workers=0,              # Simpler, fewer bugs\n",
    "    fp16=False,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20911dae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08949a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number 32218\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52b03934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/harsh/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--accuracy/f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Tue Nov  4 03:33:53 2025) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from evaluate import load\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "metric = load(\"accuracy\")\n",
    "\n",
    "preds = []\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    preds.append(eval_pred)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true=labels, y_pred=predictions, average='weighted'\n",
    "    )\n",
    "\n",
    "    accuracy = metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy['accuracy'],  # <- note: dict from `evaluate`\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0afab623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd97edba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 05:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666963</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.720128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666963</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.720128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666963</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.720128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harsh/anaconda3/envs/doc-classifier-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/harsh/anaconda3/envs/doc-classifier-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/harsh/anaconda3/envs/doc-classifier-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=0.08020662198464076, metrics={'train_runtime': 361.2726, 'train_samples_per_second': 6.643, 'train_steps_per_second': 0.415, 'total_flos': 631477872230400.0, 'train_loss': 0.08020662198464076, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc-classifier-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
