{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6defc7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f419f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace63f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Select device: prefer MPS on macOS, then CUDA, then CPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available(): \n",
    "    device = torch.device(\"cuda\")               \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using:\", device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24cbe3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31102, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a German BERT model from Hugging Face\n",
    "model_name = \"dbmdz/bert-base-german-cased\"\n",
    "\n",
    "# Load tokenizer and model for sequence classification\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=4,  # adjust if your dataset has a different number of labels\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb33c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>invoice_852.txt</td>\n",
       "      <td>rechnung rechnungsnummer  7735 rechnungsdatum ...</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reminder_628.txt</td>\n",
       "      <td>letzte mahnung sehr geehrte damen und herren, ...</td>\n",
       "      <td>reminder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>complaint_708.txt</td>\n",
       "      <td>beschwerde über lieferung am 09.11.2023 haben ...</td>\n",
       "      <td>complaint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>order_689.txt</td>\n",
       "      <td>bestellung nr. 5491 datum  11.10.2024 wir best...</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>order_851.txt</td>\n",
       "      <td>bestellung sehr geehrte damen und herren, bitt...</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>invoice_259.txt</td>\n",
       "      <td>rechnung - mettler ag kunde  prof. markus fasc...</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>contract_911.txt</td>\n",
       "      <td>mietvertrag vermieter  imhof hermann   partner...</td>\n",
       "      <td>contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>reminder_589.txt</td>\n",
       "      <td>erste zahlungserinnerung rechnung 9323 vom 31....</td>\n",
       "      <td>reminder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>order_19.txt</td>\n",
       "      <td>bestellung nr. 6577 datum  13.10.2024 wir best...</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>contract_905.txt</td>\n",
       "      <td>vertrag über zusammenarbeit dieser vertrag wir...</td>\n",
       "      <td>contract</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename                                               text  \\\n",
       "0     invoice_852.txt  rechnung rechnungsnummer  7735 rechnungsdatum ...   \n",
       "1    reminder_628.txt  letzte mahnung sehr geehrte damen und herren, ...   \n",
       "2   complaint_708.txt  beschwerde über lieferung am 09.11.2023 haben ...   \n",
       "3       order_689.txt  bestellung nr. 5491 datum  11.10.2024 wir best...   \n",
       "4       order_851.txt  bestellung sehr geehrte damen und herren, bitt...   \n",
       "..                ...                                                ...   \n",
       "95    invoice_259.txt  rechnung - mettler ag kunde  prof. markus fasc...   \n",
       "96   contract_911.txt  mietvertrag vermieter  imhof hermann   partner...   \n",
       "97   reminder_589.txt  erste zahlungserinnerung rechnung 9323 vom 31....   \n",
       "98       order_19.txt  bestellung nr. 6577 datum  13.10.2024 wir best...   \n",
       "99   contract_905.txt  vertrag über zusammenarbeit dieser vertrag wir...   \n",
       "\n",
       "        label  \n",
       "0     invoice  \n",
       "1    reminder  \n",
       "2   complaint  \n",
       "3       order  \n",
       "4       order  \n",
       "..        ...  \n",
       "95    invoice  \n",
       "96   contract  \n",
       "97   reminder  \n",
       "98      order  \n",
       "99   contract  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/data_processed/all_data.csv')\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4d2f3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rechnung rechnungsnummer  7735 rechnungsdatum ...</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>letzte mahnung sehr geehrte damen und herren, ...</td>\n",
       "      <td>reminder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beschwerde über lieferung am 09.11.2023 haben ...</td>\n",
       "      <td>complaint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bestellung nr. 5491 datum  11.10.2024 wir best...</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bestellung sehr geehrte damen und herren, bitt...</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      label\n",
       "0  rechnung rechnungsnummer  7735 rechnungsdatum ...    invoice\n",
       "1  letzte mahnung sehr geehrte damen und herren, ...   reminder\n",
       "2  beschwerde über lieferung am 09.11.2023 haben ...  complaint\n",
       "3  bestellung nr. 5491 datum  11.10.2024 wir best...      order\n",
       "4  bestellung sehr geehrte damen und herren, bitt...      order"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['text','label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b356340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c134365b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rechnung rechnungsnummer  7735 rechnungsdatum ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>letzte mahnung sehr geehrte damen und herren, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beschwerde über lieferung am 09.11.2023 haben ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bestellung nr. 5491 datum  11.10.2024 wir best...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bestellung sehr geehrte damen und herren, bitt...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  rechnung rechnungsnummer  7735 rechnungsdatum ...      2\n",
       "1  letzte mahnung sehr geehrte damen und herren, ...      4\n",
       "2  beschwerde über lieferung am 09.11.2023 haben ...      0\n",
       "3  bestellung nr. 5491 datum  11.10.2024 wir best...      3\n",
       "4  bestellung sehr geehrte damen und herren, bitt...      3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "# Encode the labels\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32f3166c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4000\n",
      "Testing set size: 500\n",
      "Validating set size: 500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Step 4: Split into train, validation, test sets (80 / 10 / 10)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"label\"], random_state=42)\n",
    "# No further splitting here — we already have pre-split train/test CSVs\n",
    "print(f'Training set size: {len(train_df)}')\n",
    "print(f'Testing set size: {len(test_df)}')\n",
    "print(f'Validating set size: {len(val_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf9a9cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "# convert the merged dataframe to a dictionary\n",
    "data_train_dict = train_df.to_dict('list')\n",
    "dataset_train = Dataset.from_dict(data_train_dict)\n",
    "data_train_dict = test_df.to_dict('list')\n",
    "dataset_test = Dataset.from_dict(data_train_dict)\n",
    "data_train_dict = val_df.to_dict('list')\n",
    "dataset_validation = Dataset.from_dict(data_train_dict)\n",
    "# create a dataset dictionary\n",
    "dataset = DatasetDict({'train': dataset_train,'test':dataset_test,'validation':dataset_validation})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "614cea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_p = []\n",
    "max_length=512\n",
    "def tokenize_data(example):\n",
    "    try:\n",
    "        return tokenizer(str(example['text']),\n",
    "                         padding='max_length',\n",
    "                         truncation=True,\n",
    "                         max_length=max_length,\n",
    "                      )\n",
    "    #truncation=True, padding=True ,max_length=128, return_overflowing_tokens=True,\n",
    "    except:\n",
    "        print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc96b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22afb73db4f487389ddc5f1260efdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67e1c37cb694774b14db9f6ce490cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbc1e2e7ad64b5ea082357d1b9c4756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize_data ,remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff17c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "model_path = \"./../models/bert_finetuned_faker_dataset\"\n",
    "training_args = TrainingArguments(\n",
    "    model_path,\n",
    "    num_train_epochs=3,                    # Better results\n",
    "    save_total_limit=1,\n",
    "    learning_rate=3e-5,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,         # Eval can handle more\n",
    "    gradient_accumulation_steps=2,         # Effective batch_size=16\n",
    "    dataloader_num_workers=0,              # Simpler, fewer bugs\n",
    "    fp16=False,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20911dae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08949a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number 32218\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52b03934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/harsh/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--accuracy/f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Tue Nov  4 03:33:53 2025) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from evaluate import load\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "metric = load(\"accuracy\")\n",
    "\n",
    "preds = []\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    preds.append(eval_pred)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true=labels, y_pred=predictions, average='weighted'\n",
    "    )\n",
    "\n",
    "    accuracy = metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy['accuracy'],  # <- note: dict from `evaluate`\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0afab623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd97edba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 31:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.674286</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.723232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.674286</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.723232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.674286</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.723232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harsh/anaconda3/envs/doc-classifier-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/harsh/anaconda3/envs/doc-classifier-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/harsh/anaconda3/envs/doc-classifier-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=750, training_loss=0.02486923246830702, metrics={'train_runtime': 1897.5976, 'train_samples_per_second': 6.324, 'train_steps_per_second': 0.395, 'total_flos': 3157389361152000.0, 'train_loss': 0.02486923246830702, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc-classifier-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
