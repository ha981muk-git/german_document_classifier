{"cells":[{"cell_type":"code","execution_count":null,"id":"b6a3ba83","metadata":{"id":"b6a3ba83","outputId":"356e3346-63c1-465a-e622-5658ab15a832"},"outputs":[{"data":{"text/plain":["1.1086626245216111"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","def cross_entropy(p, q):\n","    return -sum([p[i] * np.log(q[i]) for i in range(len(p))])\n","p = [0, 0, 0, 1]\n","q = [0.45, 0.2, 0.02, 0.33]\n","cross_entropy(p, q)"]},{"cell_type":"code","execution_count":null,"id":"j5DSHDwBZvOL","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112,"status":"ok","timestamp":1763342497736,"user":{"displayName":"Harsh Bhushan Mukhiya","userId":"00491188754078433671"},"user_tz":-60},"id":"j5DSHDwBZvOL","outputId":"aedfdfd7-08af-4478-99e4-9ad98cea8720"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"id":"XKVQuaNJZ8Zw","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14816,"status":"ok","timestamp":1763342810974,"user":{"displayName":"Harsh Bhushan Mukhiya","userId":"00491188754078433671"},"user_tz":-60},"id":"XKVQuaNJZ8Zw","outputId":"b08e76fe-0d32-42c3-e8fd-3a2f149c0e9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13640,"status":"ok","timestamp":1763343556827,"user":{"displayName":"Harsh Bhushan Mukhiya","userId":"00491188754078433671"},"user_tz":-60},"outputId":"8d7f852c-dd00-4fc2-c2ce-9b5dc7e7cd97","id":"NaYPRV85dKg2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 1)) (2.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 2)) (2.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 3)) (1.6.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 4)) (4.57.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 5)) (4.0.0)\n","Collecting evaluate (from -r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 6))\n","  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 7)) (0.2.1)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 8)) (1.11.0)\n","Collecting pymupdf (from -r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 9))\n","  Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n","Collecting pytesseract (from -r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 10))\n","  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n","Collecting metaflow (from -r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 11))\n","  Downloading metaflow-2.19.7-py2.py3-none-any.whl.metadata (6.7 kB)\n","Collecting optuna (from -r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 12))\n","  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (2.8.0+cu126)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 2)) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 2)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 2)) (2025.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 3)) (1.16.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 3)) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 3)) (3.6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 4)) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 4)) (0.36.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 4)) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 4)) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 4)) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 4)) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 4)) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 4)) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 4)) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 5)) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 5)) (0.3.8)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 5)) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 5)) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 5)) (2025.3.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 8)) (5.9.5)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from pytesseract->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 10)) (11.3.0)\n","Collecting boto3 (from metaflow->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 11))\n","  Downloading boto3-1.40.74-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 12)) (1.17.1)\n","Collecting colorlog (from optuna->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 12))\n","  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 12)) (2.0.44)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (3.4.0)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 12)) (1.3.10)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 5)) (3.13.2)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 4)) (1.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 2)) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 4)) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 4)) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 4)) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 4)) (2025.10.5)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 12)) (3.2.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (1.3.0)\n","Collecting botocore<1.41.0,>=1.40.74 (from boto3->metaflow->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 11))\n","  Downloading botocore-1.40.74-py3-none-any.whl.metadata (5.9 kB)\n","Collecting jmespath<2.0.0,>=0.7.1 (from boto3->metaflow->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 11))\n","  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n","Collecting s3transfer<0.15.0,>=0.14.0 (from boto3->metaflow->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 11))\n","  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 13)) (3.0.3)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 5)) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 5)) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 5)) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 5)) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 5)) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 5)) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /content/drive/MyDrive/Projects/german_document_classifier/requirements.txt (line 5)) (1.22.0)\n","Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n","Downloading metaflow-2.19.7-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading optuna-4.6.0-py3-none-any.whl (404 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading boto3-1.40.74-py3-none-any.whl (139 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n","Downloading botocore-1.40.74-py3-none-any.whl (14.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Downloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pytesseract, pymupdf, jmespath, colorlog, botocore, s3transfer, optuna, boto3, metaflow, evaluate\n","Successfully installed boto3-1.40.74 botocore-1.40.74 colorlog-6.10.1 evaluate-0.4.6 jmespath-1.0.1 metaflow-2.19.7 optuna-4.6.0 pymupdf-1.26.6 pytesseract-0.3.13 s3transfer-0.14.0\n"]}],"source":["!pip install -r \"/content/drive/MyDrive/Projects/german_document_classifier/requirements.txt\"\n","\n"],"id":"NaYPRV85dKg2"},{"cell_type":"code","source":[],"metadata":{"id":"ygY8USwkhd3m"},"id":"ygY8USwkhd3m","execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Projects/german_document_classifier\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763344130752,"user_tz":-60,"elapsed":26,"user":{"displayName":"Harsh Bhushan Mukhiya","userId":"00491188754078433671"}},"outputId":"793816d7-a541-49d3-8d59-7e165e3a6a99","id":"JWXPmMjHhfcH"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Projects/german_document_classifier\n"]}],"id":"JWXPmMjHhfcH"},{"cell_type":"code","source":["!python /content/drive/MyDrive/Projects/german_document_classifier/hyperparamsearch.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_cFFpUfBemvP","executionInfo":{"status":"ok","timestamp":1763344921041,"user_tz":-60,"elapsed":781267,"user":{"displayName":"Harsh Bhushan Mukhiya","userId":"00491188754078433671"}},"outputId":"59600780-1a2e-4464-ee2e-95ce607c2c32"},"id":"_cFFpUfBemvP","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["2025-11-17 01:49:05.656760: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1763344145.690216    9015 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1763344145.700616    9015 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1763344145.725489    9015 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1763344145.725527    9015 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1763344145.725535    9015 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1763344145.725542    9015 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2025-11-17 01:49:05.732448: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","ğŸš€ Training deepset/gbert-large\n","tokenizer_config.json: 100% 83.0/83.0 [00:00<00:00, 696kB/s]\n","config.json: 100% 363/363 [00:00<00:00, 3.47MB/s]\n","vocab.txt: 240kB [00:00, 26.4MB/s]\n","Map: 100% 800/800 [00:00<00:00, 1281.36 examples/s]\n","Map: 100% 100/100 [00:00<00:00, 1318.96 examples/s]\n","Map: 100% 100/100 [00:00<00:00, 1301.75 examples/s]\n","model.safetensors: 100% 1.35G/1.35G [00:16<00:00, 79.6MB/s]\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","{'loss': 1.6722, 'grad_norm': 13.24045467376709, 'learning_rate': 1.53e-05, 'epoch': 0.5}\n","{'loss': 1.6324, 'grad_norm': 10.752065658569336, 'learning_rate': 3.0000000000000004e-07, 'epoch': 1.0}\n","100% 100/100 [03:49<00:00,  2.33s/it]\n","  0% 0/7 [00:00<?, ?it/s]\u001b[A\n"," 29% 2/7 [00:01<00:03,  1.37it/s]\u001b[A\n"," 43% 3/7 [00:02<00:04,  1.03s/it]\u001b[A\n"," 57% 4/7 [00:04<00:03,  1.19s/it]\u001b[A\n"," 71% 5/7 [00:05<00:02,  1.28s/it]\u001b[A\n"," 86% 6/7 [00:07<00:01,  1.34s/it]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 1.6180588006973267, 'eval_accuracy': 0.2, 'eval_precision': 0.04, 'eval_recall': 0.2, 'eval_f1': 0.06666666666666667, 'eval_runtime': 9.1665, 'eval_samples_per_second': 10.909, 'eval_steps_per_second': 0.764, 'epoch': 1.0}\n","100% 100/100 [03:58<00:00,  2.33s/it]\n","100% 7/7 [00:07<00:00,  1.03s/it]\u001b[A\n","{'train_runtime': 263.3563, 'train_samples_per_second': 3.038, 'train_steps_per_second': 0.38, 'train_loss': 1.6522840881347656, 'epoch': 1.0}\n","100% 100/100 [04:23<00:00,  2.63s/it]\n","100% 7/7 [00:07<00:00,  1.10s/it]\n","\n","Training metrics:\n","{'eval_loss': 1.6180588006973267, 'eval_accuracy': 0.2, 'eval_precision': 0.04, 'eval_recall': 0.2, 'eval_f1': 0.06666666666666667, 'eval_runtime': 9.3451, 'eval_samples_per_second': 10.701, 'eval_steps_per_second': 0.749, 'epoch': 1.0}\n","\n","ğŸ” Evaluating on test set...\n","Map: 100% 800/800 [00:02<00:00, 387.68 examples/s]\n","Map: 100% 100/100 [00:00<00:00, 409.23 examples/s]\n","Map: 100% 100/100 [00:00<00:00, 364.83 examples/s]\n","Evaluation metrics:\n","{'accuracy': 0.2}\n","ğŸš€ Training deepset/gbert-base\n","tokenizer_config.json: 100% 83.0/83.0 [00:00<00:00, 614kB/s]\n","config.json: 100% 362/362 [00:00<00:00, 2.28MB/s]\n","vocab.txt: 240kB [00:00, 20.2MB/s]\n","Map: 100% 800/800 [00:00<00:00, 1323.60 examples/s]\n","Map: 100% 100/100 [00:00<00:00, 1294.11 examples/s]\n","Map: 100% 100/100 [00:00<00:00, 1270.97 examples/s]\n","model.safetensors: 100% 442M/442M [00:04<00:00, 95.7MB/s]\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","{'loss': 0.5764, 'grad_norm': 0.8450059294700623, 'learning_rate': 1.53e-05, 'epoch': 0.5}\n","{'loss': 0.0176, 'grad_norm': 0.1449335813522339, 'learning_rate': 3.0000000000000004e-07, 'epoch': 1.0}\n","100% 100/100 [01:14<00:00,  1.37it/s]\n","  0% 0/7 [00:00<?, ?it/s]\u001b[A\n"," 29% 2/7 [00:00<00:01,  4.23it/s]\u001b[A\n"," 43% 3/7 [00:00<00:01,  3.04it/s]\u001b[A\n"," 57% 4/7 [00:01<00:01,  2.62it/s]\u001b[A\n"," 71% 5/7 [00:01<00:00,  2.42it/s]\u001b[A\n"," 86% 6/7 [00:02<00:00,  2.34it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.009246462024748325, 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': 2.924, 'eval_samples_per_second': 34.199, 'eval_steps_per_second': 2.394, 'epoch': 1.0}\n","100% 100/100 [01:17<00:00,  1.37it/s]\n","100% 7/7 [00:02<00:00,  3.05it/s]\u001b[A\n","{'train_runtime': 82.698, 'train_samples_per_second': 9.674, 'train_steps_per_second': 1.209, 'train_loss': 0.2970194584131241, 'epoch': 1.0}\n","100% 100/100 [01:22<00:00,  1.21it/s]\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Projects/german_document_classifier/main.py\", line 27, in <module>\n","    train_metrics = train_model(\n","                    ^^^^^^^^^^^^\n","  File \"/content/drive/MyDrive/Projects/german_document_classifier/src/train.py\", line 100, in train_model\n","    model.save_pretrained(save_path)\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 4173, in save_pretrained\n","    safe_save_file(shard, os.path.join(save_directory, shard_file), metadata=metadata)\n","  File \"/usr/local/lib/python3.12/dist-packages/safetensors/torch.py\", line 352, in save_file\n","    serialize_file(_flatten(tensors), filename, metadata=metadata)\n","                   ^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/safetensors/torch.py\", line 589, in _flatten\n","    \"data\": _tobytes(v, k),\n","            ^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/safetensors/torch.py\", line 507, in _tobytes\n","    tensor = tensor.to(\"cpu\")\n","             ^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Projects/german_document_classifier\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mGTd5CwagAit","executionInfo":{"status":"ok","timestamp":1763344130752,"user_tz":-60,"elapsed":26,"user":{"displayName":"Harsh Bhushan Mukhiya","userId":"00491188754078433671"}},"outputId":"793816d7-a541-49d3-8d59-7e165e3a6a99"},"id":"mGTd5CwagAit","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Projects/german_document_classifier\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"b6smbYdbkXbW"},"id":"b6smbYdbkXbW","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vVWxw4K3gDBQ","executionInfo":{"status":"ok","timestamp":1763345287329,"user_tz":-60,"elapsed":106,"user":{"displayName":"Harsh Bhushan Mukhiya","userId":"00491188754078433671"}},"outputId":"70d90410-267c-4e41-a5f1-50c38ccaea83"},"id":"vVWxw4K3gDBQ","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Projects/german_document_classifier\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"1XwmWkbKkdYF"},"id":"1XwmWkbKkdYF","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/drive/MyDrive/Projects/german_document_classifier/hyperparamsearch.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763345333650,"user_tz":-60,"elapsed":31526,"user":{"displayName":"Harsh Bhushan Mukhiya","userId":"00491188754078433671"}},"outputId":"93620264-9370-4e10-dec0-c3d8b428deb1","id":"Z2BV33bskeRR"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["2025-11-17 02:08:29.454155: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1763345309.473564   14067 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1763345309.479460   14067 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1763345309.494521   14067 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1763345309.494544   14067 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1763345309.494548   14067 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1763345309.494553   14067 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2025-11-17 02:08:29.498994: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","ğŸš€ Starting MULTI-MODEL Optuna HPO...\n","ğŸ” Running HPO for model: deepset/gbert-large\n","\u001b[32m[I 2025-11-17 02:08:38,074]\u001b[0m A new study created in RDB with name: hpo_deepset_gbert-large\u001b[0m\n","Map: 100% 800/800 [00:00<00:00, 1332.18 examples/s]\n","Map: 100% 100/100 [00:00<00:00, 1286.21 examples/s]\n","Map: 100% 100/100 [00:00<00:00, 1151.46 examples/s]\n","  1% 1/150 [00:04<12:14,  4.93s/it]\u001b[33m[W 2025-11-17 02:08:51,231]\u001b[0m Trial 0 failed with parameters: {'learning_rate': 1.7254630961731215e-05, 'dropout': 0.025490710648344794, 'weight_decay': 0.11115572845385145, 'batch_size': 16} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 58.12 MiB is free. Process 200389 has 14.68 GiB memory in use. Of the allocated memory 14.38 GiB is allocated by PyTorch, and 179.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\u001b[0m\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n","    value_or_values = func(trial)\n","                      ^^^^^^^^^^^\n","  File \"/content/drive/MyDrive/Projects/german_document_classifier/hyperparamsearch.py\", line 34, in objective\n","    metrics = train_model(\n","              ^^^^^^^^^^^^\n","  File \"/content/drive/MyDrive/Projects/german_document_classifier/src/train.py\", line 97, in train_model\n","    trainer.train()\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2325, in train\n","    return inner_training_loop(\n","           ^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2674, in _inner_training_loop\n","    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 4020, in training_step\n","    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 4110, in compute_loss\n","    outputs = model(**inputs)\n","              ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\", line 1482, in forward\n","    outputs = self.bert(\n","              ^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\", line 1000, in forward\n","    encoder_outputs = self.encoder(\n","                      ^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\", line 650, in forward\n","    layer_outputs = layer_module(\n","                    ^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\", line 94, in __call__\n","    return super().__call__(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\", line 588, in forward\n","    layer_output = apply_chunking_to_forward(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/pytorch_utils.py\", line 257, in apply_chunking_to_forward\n","    return forward_fn(*input_tensors)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\", line 596, in feed_forward_chunk\n","    intermediate_output = self.intermediate(attention_output)\n","                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\", line 512, in forward\n","    hidden_states = self.dense(hidden_states)\n","                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n","    return F.linear(input, self.weight, self.bias)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 58.12 MiB is free. Process 200389 has 14.68 GiB memory in use. Of the allocated memory 14.38 GiB is allocated by PyTorch, and 179.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","\u001b[33m[W 2025-11-17 02:08:51,249]\u001b[0m Trial 0 failed with value None.\u001b[0m\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Projects/german_document_classifier/hyperparamsearch.py\", line 84, in <module>\n","    study.optimize(objective, n_trials=10)\n","  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/study.py\", line 490, in optimize\n","    _optimize(\n","  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\", line 67, in _optimize\n","    _optimize_sequential(\n","  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\", line 164, in _optimize_sequential\n","    frozen_trial_id = _run_trial(study, func, catch)\n","                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\", line 262, in _run_trial\n","    raise func_err\n","  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n","    value_or_values = func(trial)\n","                      ^^^^^^^^^^^\n","  File \"/content/drive/MyDrive/Projects/german_document_classifier/hyperparamsearch.py\", line 34, in objective\n","    metrics = train_model(\n","              ^^^^^^^^^^^^\n","  File \"/content/drive/MyDrive/Projects/german_document_classifier/src/train.py\", line 97, in train_model\n","    trainer.train()\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2325, in train\n","    return inner_training_loop(\n","           ^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2674, in _inner_training_loop\n","    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 4020, in training_step\n","    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 4110, in compute_loss\n","    outputs = model(**inputs)\n","              ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\", line 1482, in forward\n","    outputs = self.bert(\n","              ^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\", line 1000, in forward\n","    encoder_outputs = self.encoder(\n","                      ^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\", line 650, in forward\n","    layer_outputs = layer_module(\n","                    ^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\", line 94, in __call__\n","    return super().__call__(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\", line 588, in forward\n","    layer_output = apply_chunking_to_forward(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/pytorch_utils.py\", line 257, in apply_chunking_to_forward\n","    return forward_fn(*input_tensors)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\", line 596, in feed_forward_chunk\n","    intermediate_output = self.intermediate(attention_output)\n","                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\", line 512, in forward\n","    hidden_states = self.dense(hidden_states)\n","                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n","    return F.linear(input, self.weight, self.bias)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 58.12 MiB is free. Process 200389 has 14.68 GiB memory in use. Of the allocated memory 14.38 GiB is allocated by PyTorch, and 179.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","  1%|          | 1/150 [00:07<18:33,  7.48s/it]\n"]}],"id":"Z2BV33bskeRR"}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.19"}},"nbformat":4,"nbformat_minor":5}